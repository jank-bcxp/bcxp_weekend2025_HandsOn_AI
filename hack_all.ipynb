{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCxP GenAI Hands-on Sessions\n",
    "\n",
    "In diesem Jupyter Notebook finden sich f√ºnf Hands-On Session zur Verwendung von generativer KI in Software Anwendungen. \n",
    "\n",
    "1. OpenAI API - Basics\n",
    "2. OpenAI API - Function Calling\n",
    "3. Semantic Search & RAG\n",
    "4. OpenAI API - Working with Files\n",
    "5. Generative UI\n",
    "\n",
    "Es empfiehlt sich mit Part 1 zu beginnen. Die weiteren Teile bauen nicht aufeinander auf und k√∂nnen in beliebeger Reihenfolge bearbeitet werden. \n",
    "\n",
    "Thematisch drehen sich die Sessions um die Entwicklung eines digitalen Kellners f√ºr ein Pizzeria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install openai sentence-transformers matplotlib scikit-learn umap-learn plotly faiss-cpu numpy tabulate pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict\n",
    "import io\n",
    "\n",
    "from hack_helpers import OPENAI_API_KEY\n",
    "from menu import MENU\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: OpenAI API Basics\n",
    "\n",
    "## Finde die passende Pizza\n",
    "\n",
    "Task: Ein Kunde soll basierend auf der Beschreibung einer Speise eine passende Bestelloption aus den verf√ºgbaren Speisen (definiert in menu.py) finden k√∂nnen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendung von OpenAI API **ohne Structured Outputs**:\n",
    "\n",
    "\n",
    "F√ºhre die n√§chste Zelle aus und beobachte die Ausgabe. Die Ausgabe ist Textbasiert - wie bei der Nutzung von ChatGPT √ºber die Web- oder die Desktop App. Eine programmatische Verwendung des Outputs ist mit dieser 'unstrukturierten' Ausgabe ungeeignet. \n",
    "\n",
    "**Aufgabe:** F√ºhre die n√§chste Zelle mehrmals aus und ver√§ndere den User-Input. Beobachte, wie sich das Format der Ausgabe immer wieder ver√§ndert.\n",
    "\n",
    "**Aufgabe:** Passe den System-Prompt an, um die Struktur der Ausgabe vorzugegeben (Beispielsweise \"Gib den Namen genau einer Speise an\"). Versuche dann den System-Prompt zu 'hacken' und mit einem beliebigen User-Input eine Ausgabe zu erhalten, die nicht der geforderten Struktur entspricht. Ist dies m√∂glich? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü•° Men√º\n",
    "# for item in MENU:\n",
    "#     print(item)\n",
    "\n",
    "# üí¨ Beispiel-Eingabe\n",
    "user_input = \"Ich m√∂chte gerne etwas mit scharfer Salami oder Pilzen.\"\n",
    "\n",
    "# üß† API-Aufruf\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"Du bist ein digitaler Kellner. W√§hle den passenden Eintrag aus der Speisekarte aus.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Speisekarte:\\n{json.dumps(MENU, ensure_ascii=False)}\\n\\nBestellung: {user_input}\"} # Hier √ºbergeben wir die Speisekarte und die Bestellung\" \n",
    "    ],\n",
    ")\n",
    "\n",
    "# üì§ Ausgabe anzeigen\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendung von OpenAI API **mit Structured Outputs**:\n",
    "\n",
    "Mit _structured outputs_ kann sichergestellt werden, dass das Format der Ausgabe immer dem selben JSON Schema entspricht. JSON (JavaScript Object Notation) ist ein leichtgewichtiges, textbasiertes Format zur Darstellung strukturierter Daten. Es wird h√§ufig in der Webentwicklung und bei APIs zur √úbertragung von Daten zwischen Client und Server verwendet. \n",
    "\n",
    "**Aufgabe:** Mache Anpassungen, damit nur eine Speise f√ºr die Bestellung empfohlen wird. Welche M√∂glichkeiten gibt es dies zu realisieren (passe das Prompt oder das Schema an). Welche Vorteile/Nachteile gibt es jeweils bei den unterschiedlichen Ans√§tzen? Kannst du den 'Prompt-Hacking' Ansatz aus der vorherigen Aufgabe auch unter der Verwendung von _structured outputs_ reproduzieren? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí¨ Beispiel-Eingabe\n",
    "# user_input = \"Ich habe Lust auf eine w√ºrzige Pizza mit Salami.\" # Input mit einer Option\n",
    "user_input = \"Ich h√§tte gerne etwas mit scharfer Salami oder Peperoni.\" # Input mit mehreren Optionen\n",
    "\n",
    "# JSON Schema f√ºr Ausgabe: Liste von Speisen, wobei eine Speise aus Id, Name, Beschreibung, Kategorie und Preis bestehen.\n",
    "menu_items_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"category\": {\"type\": \"string\"},\n",
    "                    \"price\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"id\", \"name\", \"description\", \"category\", \"price\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"items\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "# üß† API-Aufruf\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"Du bist ein digitaler Kellner. W√§hle den passenden Eintrag aus der Speisekarte aus.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Speisekarte:\\n{json.dumps(MENU, ensure_ascii=False)}\\n\\nBestellung: {user_input}\"}\n",
    "    ],\n",
    "    # Gew√ºnschtes Ausgabeformat wird API-Aufruff √ºbergeben\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"menu_item\",\n",
    "            \"schema\": menu_items_schema,\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "recommendations = json.loads(response.output_text)[\"items\"]\n",
    "\n",
    "# üì§ Nun k√∂nnen wir √ºber Speiseempfehlung iterieren und diese beispielsweise Schritt f√ºr Schritt Anzeigen\n",
    "for item in recommendations:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: OpenAI API Function Calling\n",
    "\n",
    "## Pizza Buchungssystem\n",
    "\n",
    "Task: Der digitale Kellner soll Bestellungen in einer Bestellapp registrieren k√∂nnen. Die Bestellapp stellt dazu eine Funktion \"add_item_to_order\" bereit. Diese bekommt als Parameter die Id eines Menueintrags √ºbergeben und f√ºgt den Men√ºeintrag dann zu einer Liste hinzu.  \n",
    "\n",
    "ChatGPT unterst√ºtzt sogenanntes Function Calling. Dabei erh√§lt das Modell eine Beschreibung verf√ºgbarer Funktionen inklusive ihrer Argumente. Basierend auf dem Nutzereingaben kann ChatGPT passende Funktionsaufrufe vorschlagen, die anschlie√üend lokal ausgef√ºhrt werden k√∂nnen.\n",
    "\n",
    "Zwar l√§sst sich eine vergleichbare Funktionalit√§t grunds√§tzlich auch √ºber strukturierte Ausgaben realisieren, jedoch stellt Function Calling eine einfachere und standardisierte Methode daf√ºr dar.\n",
    "\n",
    "**Aufgabe:** Erweitere die Funktionalit√§t um eine Funktion \"remove_item_from_order\", welche die id eines bestelltem Items √ºbergeben bekommt und dieses aus der Liste l√∂scht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "# Bestellung (als globale Liste)\n",
    "bestellung: List[Dict] = []\n",
    "\n",
    "def add_item_to_order(item_id: str):\n",
    "    item = next((entry for entry in MENU if entry[\"id\"] == item_id), None)\n",
    "    if item:\n",
    "        bestellung.append(item)\n",
    "        return f\"{item['name']} wurde zur Bestellung hinzugef√ºgt.\"\n",
    "    return f\"Item mit ID {item_id} nicht gefunden.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"add_item_to_order\",\n",
    "        \"description\": \"F√ºgt ein Item der Bestellung hinzu.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"item_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Die ID des hinzuzuf√ºgenden Items.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"item_id\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_waiter(user_input: str):\n",
    "    print(f\"üë§ Input: {user_input}\")\n",
    "    # Erstellung der Eingabenachrichten\n",
    "    input_messages = [\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"Du bist ein digitaler Kellner. Nimm Bestellungen auf und beantworte Fragen zum Men√º.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": f\"Speisekarte:\\n{json.dumps(MENU, ensure_ascii=False)}\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input,\n",
    "        },\n",
    "\n",
    "    ]\n",
    "\n",
    "    # API-Aufruf mit Function Calling\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\", input=input_messages, tools=tools, tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type != \"function_call\":\n",
    "            print(f\"ü§ñ Antwort: {response.output_text}\")\n",
    "            continue\n",
    "\n",
    "        name = tool_call.name\n",
    "        args = json.loads(tool_call.arguments)\n",
    "\n",
    "        if name == \"add_item_to_order\":\n",
    "            result = add_item_to_order(args[\"item_id\"])\n",
    "        print(f\"üîß Function Call: {name}({args}) ‚ûú {result}\")\n",
    "\n",
    "    # Anzeige der aktuellen Bestellung\n",
    "    print(\"üì¶ Aktuelle Bestellung:\")\n",
    "    for item in bestellung:\n",
    "        print(f\"- {item['name']} ({item['preis']} ‚Ç¨)\")\n",
    "    print('-' * 40+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_waiter(\"Wie geht es dir? \")\n",
    "chat_with_waiter(\"Ich m√∂chte gerne eine Pizza Diavola und eine Cola bestellen.\")\n",
    "chat_with_waiter(\"Noch eine Cola bitte\")\n",
    "chat_with_waiter(\"Bitte entferne die Cola wieder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Semantic Search & Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings & Basic Similarity Search\n",
    "\n",
    "In der Einf√ºhrung zu LLMs haben wir gesehen, wie Begriffe in einen Vektorraum eingebettet (embedded) und numerisch dargestellt werden k√∂nnen. Der Vektor eines Wortes - das **Embedding** - repr√§sentiert dabei dessen Bedeutung. \n",
    "Bei einer **syntaktischen** Suche nach dem Begriff \"Unterkunft\" in einem Dokument, werden genau diejenigen W√∂rter gesucht, die Zeichen f√ºr Zeichen mit \"Unterkunft\" √ºbereinstimmen. Bei der **semantischen** Suche werden hingegen alle W√∂rter gesucht, die eine √§hnliche Bedeutung wie \"Unterkunft\" besitzen. Das sind diejenigen W√∂rter, die im Vektorraum 'nahe' am Vektor von \"Unterkunft\" liegen. Neben Unterkunft w√ºrden so auch Begriffe wie \"Ferienwohnung\" oder \"Hotel\" auftauchen. Nachfolgend werden wir sehen, wie eine semantische Suche implementiert werden kann. Da der Vektorraum ein kontinuierlicher Raum ist werden bei der semantischen Suche entweder die top-k Ergebnisse verwendet die am n√§chsten sind oder es wird ein fester Schwellenwert verwendet, der definiert ob ein Kandidat nah genug am gesuchten Begriff ist um als 'Match' zu gelten.\n",
    "\n",
    "Um Embeddings zu erstellen k√∂nnen unterschiedliche Sprachmodelle verwendet werden. Beispielsweise sind _SentenceTransformer_ eine ressourcen-schonende und frei verf√ºgbare Alternative zu kostenpflichtigen Modellen wie von OpenAI, die auch lokal laufen k√∂nnen. Der einfachheit halber verwenden wir hier aber die OpenAI API um Embeddings zu erzeugen.\n",
    "\n",
    "UMAP (Uniform Manifold Approximation and Projection) ist ein Verfahren zur Dimensionsreduktion, das hochdimensionale Vektoren ‚Äì z.‚ÄØB. Embeddings aus Sprache ‚Äì in einen niederdimensionalen Raum wie 2D f√ºr Darstellungszwecke abbildet. Es versucht dabei, semantische N√§he (z.‚ÄØB. zwischen Texten) m√∂glichst gut zu bewahren, indem es lokale Nachbarschaften erh√§lt.\n",
    "\n",
    "‚ö†Ô∏è Wichtig: Die sichtbare Distanz im 2D-Plot entspricht nicht exakt der tats√§chlichen √Ñhnlichkeit im urspr√ºnglichen Vektorraum. Die Projektion ist eine visuelle Ann√§herung, keine metrische 1:1-Abbildung.\n",
    "\n",
    "F√ºhre die n√§chste Zelle aus um f√ºr jeden Men√º Eintrag die N√§he zur User-Eingabe zu bestimmen und um die Embeddings der Speisen aus der Speisekarte und den User Input mittels UMAP in einem Plot zu visualisieren.\n",
    "\n",
    "## Finde die passende Pizza mit Semantic Search\n",
    "\n",
    "Task: Ein Kunde soll basierend auf der Beschreibung einer Speise eine passende Bestelloption finden k√∂nnen. \n",
    "**Aufgabe:** F√ºge der Karte einige Getr√§nke und Salate hinzu und beobachte wie sich diese in die UMAP Projektion einf√ºgen. F√ºge unpassende Nutzer-Eingaben ein und beobacht den Score und wie sich die Anfrage in die UMAP Projektion einf√ºgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üó£ Benutzereingabe\n",
    "user_input = \"Ich habe Lust auf eine spicy Pizza.\"\n",
    "\n",
    "# üßæ Strings zur Embedding-Vorbereitung\n",
    "menu_texts = [f\"{item['name']} ‚Äì {item['beschreibung']}\" for item in MENU]\n",
    "texts_to_embed = [user_input] + menu_texts  # User prompt + all items\n",
    "\n",
    "# üß† Embedding-Berechnung mit OpenAI\n",
    "response = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\", input=texts_to_embed\n",
    ")\n",
    "embeddings = [np.array(d.embedding) for d in response.data]\n",
    "\n",
    "# üßÆ Vektorvergleich (cosine similarity)\n",
    "user_embedding = embeddings[0] # User Prompt embedding\n",
    "menu_embeddings = embeddings[1:] # Menu embeddings\n",
    "# Hier wird die Cosine Similarity zwischen dem User-Embedding und den Men√º-Embeddings berechnet\n",
    "# F√ºr viele Men√º-Items und wechselnden Anfragen kann dies sehr ineffizient sein\n",
    "similarities = cosine_similarity([user_embedding], menu_embeddings)[0] \n",
    "\n",
    "# ü•á Sortierte Ergebnisse\n",
    "results = []\n",
    "for idx, score in sorted(enumerate(similarities), key=lambda x: x[1], reverse=True):\n",
    "    item = MENU[idx]\n",
    "    results.append(\n",
    "        {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"score\": round(score, 3),\n",
    "            \"description\": item[\"beschreibung\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# üìä Ausgabe als DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "plot_umap(user_embedding, menu_embeddings, MENU, similarity_scores=similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS f√ºr schnelle Similarity Search bei gro√üen Datenmengen\n",
    "\n",
    "**FAISS** (Facebook AI Similarity Search) ist eine Bibliothek f√ºr schnelle und skalierbare √§hnlichkeitssuche auf Vektoren.\n",
    "Sie erm√∂glicht eine effiziente Nearest-Neighbor-Suche ‚Äî n√ºtzlich f√ºr semantische Suche, Reccomendation Systems, Clustering usw.\n",
    "\n",
    "Hauptmerkmale:\n",
    "- Funktioniert mit hochdimensionalen Embeddings (z.‚ÄØB. von SentenceTransformers)\n",
    "- Erm√∂glicht Kosinus-√Ñhnlichkeit (√ºber normalisierte Vektoren und inneres Produkt) f√ºr semantische √Ñhnlichkeit\n",
    "- Skaliert auf Millionen oder Milliarden von Vektoren\n",
    "- Indizes k√∂nnen auf der Festplatte gespeichert und geladen werden ‚Äì Metadaten m√ºssen jedoch separat verwaltet werden\n",
    "\n",
    "Typischer Workflow:\n",
    "1.\tWandle deine Objekte (z.‚ÄØB. Texte) mit einem Embedding-Modell in dichte Vektoren um.\n",
    "2.\tSpeichere diese Vektoren in einem FAISS-Index (z.‚ÄØB. IndexFlatIP oder IndexHNSWFlat).\n",
    "3.\tKodierst du eine Anfrage (Query), kannst du die top-k √§hnlichsten Objekte suchen.\n",
    "\n",
    "**Aufgabe 1**: Finde ein Beispiel f√ºr eine User Query, f√ºr welches das Ergebnis mit dem besten √Ñhnlichkeitsscore nicht zur Query passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EMBEDDING SETUP ===\n",
    "# Wir wollen Embeddings erzeugen f√ºr Name + Beschreibung der Men√ºpunkte\n",
    "menu_texts = [f\"{item['name']}: {item['beschreibung']}\" for item in MENU]\n",
    "\n",
    "# Generiere die Embeddings f√ºr die Men√ºtexte mit OpenAI\n",
    "response = openai_client.embeddings.create(model=\"text-embedding-3-small\", input=menu_texts)\n",
    "embeddings = np.array([d.embedding for d in response.data], dtype=np.float32)\n",
    "\n",
    "# === FAISS VECTOR INDEX ===\n",
    "# Normalisierung wird ben√∂tigt um zusammen mit inner product (dot product) die Cosine Similarity zu berechnen, welche die √Ñhnlichkeit der Vektoren beschreibt\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dim = embeddings.shape[1] # Dimension der Vektoren\n",
    "index = faiss.IndexFlatIP(dim) # Initialisierung des Indexes mit inner product (dot product)\n",
    "index.add(embeddings) # Vektoren dem Index hinzuf√ºgen\n",
    "\n",
    "# === MEN√ú ABFRAGE ===\n",
    "def retrieve_menu_items(query: str, top_k: int = 10) -> List[Dict]:\n",
    "    # Step 1: Generiere Embedding f√ºr die User Abfrage\n",
    "    response = openai_client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\", input=[query]\n",
    "    )\n",
    "    query_vec = np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # Step 2: Normalisiere den Vektor f√ºr die Cosine Similarity\n",
    "    faiss.normalize_L2(query_vec)\n",
    "\n",
    "    # Step 3: Suche im FAISS Index nach den √§hnlichsten Vektoren\n",
    "    distances, indices = index.search(query_vec, top_k)\n",
    "\n",
    "    # Step 4: Erstelle eine Liste von Men√ºpunkten mit den entsprechenden √Ñhnlichkeitswerten\n",
    "    return list(zip(indices[0], distances[0]))\n",
    "\n",
    "print(\"FAISS Index Description\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Index Type      : {type(index).__name__}\")\n",
    "print(f\"Dimension (D)   : {index.d}\")\n",
    "print(f\"Vectors Stored  : {index.ntotal}\")\n",
    "print(\"-\" * 30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXAMPLE USAGE ===\n",
    "user_query = \"Ich h√§tte gerne etwas mit Pilzen\"\n",
    "retrieved_results = retrieve_menu_items(user_query)\n",
    "for idx, score in retrieved_results:\n",
    "    print(f\"- {MENU[idx]['name']} (score: {score}): {MENU[idx]['beschreibung']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG) mit FAISS und OpenAI API\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) ist ein KI-Ansatz, der generative Sprachmodelle (z.‚ÄØB. GPT) mit einer externen Wissensquelle kombiniert. Dabei werden relevante Informationen zur Benutzeranfrage zuerst aus einer Datenbank oder Dokumentensammlung _retrieved_ (abgerufen), wie in folgendem Beispiel aus unserem FAISS Index, und anschlie√üend von einem genertiven Modell in die Generierung der Antwort einbezogen. \n",
    "\n",
    "- Ein RAG Ansatz kann verwendet werden, wenn auf einem gro√üen Datensatz gearbeitet werden muss, welcher zu gro√ü f√ºr den Kontext des Sprachmodells ist.\n",
    "- Au√üerdem k√∂nnen durch die Reduzierung des LLM Inputs auf relevante Eintr√§ge Kosten gesenkt werden (Anzahl der Input-Tokens sinkt).\n",
    "\n",
    "**Aufgabe:** √úberlege dir Vor und Nachteile eines RAG Ansatzes. In welchen F√§llen kann der RAG Ansatz zu schlechten Ergebnissen f√ºhren? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_items_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"category\": {\"type\": \"string\"},\n",
    "                    \"price\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"id\", \"name\", \"description\", \"category\", \"price\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"items\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "user_query = \"Ich h√§tte gerne etwas mit Pilzen aber ohne Tr√ºffel.\"\n",
    "retrieved_results = retrieve_menu_items(user_query)\n",
    "print(\"Vorselektierte Eintr√§ge aus dem Men√º:\\n\")\n",
    "for idx, score in retrieved_results:\n",
    "    print(f\"- {MENU[idx]['name']} (score: {score}): {MENU[idx]['beschreibung']}\")\n",
    "retrieved_menu_items = [MENU[idx] for idx, _ in retrieved_results]\n",
    "\n",
    "# üß† API-Aufruf\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Du bist ein digitaler Kellner. W√§hle genau eine passende Speise aus den folgenden vorselektierten Speisen aus, welche die Kriterien aus der Kundenbestellung am ehesten erf√ºllt:\\n{json.dumps(retrieved_menu_items, ensure_ascii=False)}\\n\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{user_query}\",\n",
    "        },\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"menu_item\",\n",
    "            \"schema\": menu_items_schema,\n",
    "            \"strict\": True,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "recommendations = json.loads(response.output_text)[\"items\"]\n",
    "\n",
    "# üì§ Ausgabe anzeigen\n",
    "print(\"\\nEmpfohlene Speise:\")\n",
    "for item in recommendations:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Embedding Generation (Bonus)\n",
    "\n",
    "Nachfolgend findet sich ein Beispiel mit der Verwendung eines lokalen Sentence-Transformer Modells f√ºr das Erstellen der Embeddings der Speisekarte und des User-Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hack_helpers import plot_umap\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# üó£ 2. Benutzereingabe\n",
    "user_input = \"Ich habe Lust auf eine spicy Pizza.\"\n",
    "\n",
    "# üß† 3. Modell laden (z.‚ÄØB. multilingual + performant)\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# üßÆ 4. Embeddings berechnen\n",
    "menu_texts = [f\"{item['name']} ‚Äì {item['beschreibung']}\" for item in MENU] # Hier wird die Speisekarte in emeddable Strings umgewandelt\n",
    "menu_embeddings = model.encode(menu_texts, convert_to_tensor=True) # Hier werden die Embeddings f√ºr die gesamte Speisekarte berechnet\n",
    "user_embedding = model.encode(user_input, convert_to_tensor=True) # Hier wird das Embedding f√ºr die Benutzereingabe berechnet\n",
    "\n",
    "# TODO Print ein Embedding um die Vectorrepr√§sentation zu sehen\n",
    "# print(user_embedding)\n",
    "\n",
    "# üîé 5. √Ñhnlichkeit berechnen\n",
    "cos_scores = util.cos_sim(user_embedding, menu_embeddings)[0] # Hier wird die √Ñhnlichkeit zwischen der Benutzereingabe und den Speisen mittels cosine similarity berechnet\n",
    "\n",
    "# ü•á 6. Sorted results\n",
    "top_results = sorted(list(enumerate(cos_scores)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# üì§ 7. Ausgabe strukturieren\n",
    "results = []\n",
    "for idx, score in top_results:\n",
    "    item = MENU[idx]\n",
    "    results.append(\n",
    "        {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"score\": round(score.item(), 3),\n",
    "            \"description\": item[\"beschreibung\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# üìä Als DataFrame anzeigen\n",
    "pd.set_option(\"display.width\", 200)  # Increase pd width to print correctly\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "plot_umap(user_embedding, menu_embeddings, MENU, similarity_scores=cos_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Working with Files\n",
    "\n",
    "## Finde die passende Pizza\n",
    "\n",
    "Task: Im Folgenden Szenario wird die Speisekarte von einer exteren Agentur erstellt und ist nur als PDF verf√ºgbar. Im folgenden passen wir unseren digitalen Kellner so an, dass er mit der PDF Speisekarte arbeitet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendung von OpenAI API mit **Structured Outputs** und **Files** Input:\n",
    "\n",
    "Multimodale Modelle sind KI-Modelle, die Informationen aus verschiedenen Modalit√§ten ‚Äì etwa Text, Bilder, Audio oder strukturierte Daten ‚Äì gleichzeitig verarbeiten und kombinieren k√∂nnen. Das unterscheidet sie von klassischen Modellen, die nur mit einer einzigen Eingabemodalit√§t (z.‚ÄØB. nur Text) umgehen k√∂nnen.\n",
    "\n",
    "GPT 4.1. beispielsweise kann multimodalen Input wie Text, PDFs oder Bilder verarbeiten. Im folgenden Beispiel verwenden wir `gpt-4.1` zur Verarbeitung eines Nutzer-Inputs *und* einer PDF-Datei (z.‚ÄØB. einer Speisekarte).\n",
    "\n",
    "**Aufgabe:** Neben Speisen f√ºr die Pizzeria soll der Kellner auch Speisen f√ºr das Restaurant \"Naherholungsgebiet\" in Stuttgart aufnehmen k√∂nnen. Erweitere den API Aufruf, sodass beide Speisekarten √ºbergeben werden. F√ºge im Systemprompt den aktuellen Tag hinzu und mache Anpassungen, dass nur die f√ºr den Tag verf√ºgbaren Speisen des Naherholungsgebiets ber√ºcksichtigt werden. Erweitere das Output-Schema so, dass auch das entsprechende Restaurant (\"Naherholungsgebite\" oder \"Salve\") in der Ausgabe enthalten sind. Finde Bestellungen f√ºr die Speisen aus beiden Restaurants empfohlen werden. Passe den Prompt wo n√∂tig an. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Ich habe Lust auf was mit Gorgonzola.\"\n",
    "\n",
    "with open(\"speisekarte.pdf\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "speisekarte_base64_string = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "menu_items_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"category\": {\"type\": \"string\"},\n",
    "                    \"price\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"id\", \"name\", \"description\", \"category\", \"price\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"items\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "# üß† API-Aufruf\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Du bist ein digitaler Kellner. W√§hle passende Eintr√§ge aus der Speisekarte.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"filename\": \"speisekarte.pdf\",\n",
    "                    \"file_data\": f\"data:application/pdf;base64,{speisekarte_base64_string}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": f\"{user_input}\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"menu_item\",\n",
    "            \"schema\": menu_items_schema,\n",
    "            \"strict\": True,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "recommendations = json.loads(response.output_text)[\"items\"]\n",
    "\n",
    "# üì§ Ausgabe anzeigen\n",
    "for item in recommendations:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Generative UI\n",
    "\n",
    "Generative UI bezeichnet eine Benutzerschnittstelle, die sich dynamisch und kontextabh√§ngig durch generative KI-Modelle anpassen oder erzeugen l√§sst \n",
    "\n",
    "### Beispiel\n",
    "Ein Nutzer fragt:\n",
    "‚ÄûZeig mir meine Verkaufszahlen der letzten 3 Monate im Vergleich zu Q1 2024.‚Äú\n",
    "‚Üí Die generative UI erstellt automatisch ein Dashboard mit dem passenden Plot, Filter und Interpretation ‚Äì ohne dass das Layout oder die Abfrage vorher explizit programmiert war.\n",
    "\n",
    "Im Folgenden wollen wir dem Nutzer erm√∂glichen Plots zu prompten und damit eine einfache M√∂glichkeit bieten den bereitgestellten Datensatz von Pizzaverkaufszahlen zu analysieren.\n",
    "\n",
    "**Aufgabe:** Optimiere den System-Prompt, um fehlerhaften Code im Output zu vermeiden (General Task Description, Output Rules). Versuche alle Beispiele zum Laufen zu bringen! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Pizzaverk√§ufe-Daten aus einer CSV-Datei aus GitHub\n",
    "url = \"https://raw.githubusercontent.com/santoshkr23/Pizzasales/main/pizza_sales_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Zeige Informationen √ºber den DataFrame an \n",
    "df.info()\n",
    "# Zeige die ersten 5 Zeilen des DataFrames an\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "# General Task Description\n",
    "Your task is to write complete Python code that - based on the provided pandas DataFrame (df) that includes pizza sales data and a user-specified plot request - produces a corresponding plotly.graph_objects.Figure.\n",
    "The code must:\n",
    "\t1.\tTransform the provided df through filtering, grouping, aggregating, or other methods to prepare the data for visualization.\n",
    "\t2.\tGenerate a well-styled plotly.graph_objects.Figure that fully satisfies the user's description and uses the transformed data.\n",
    "\n",
    "# Output Rules (must be followed exactly)\n",
    "    - ...\n",
    "    \n",
    "\n",
    "# Data\n",
    "## df.info() output\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 48620 entries, 0 to 48619\n",
    "    Data columns (total 12 columns):\n",
    "    #   Column             Non-Null Count  Dtype  \n",
    "    ---  ------             --------------  -----  \n",
    "    0   pizza_id           48620 non-null  int64  \n",
    "    1   order_id           48620 non-null  int64  \n",
    "    2   pizza_name_id      48620 non-null  object \n",
    "    3   quantity           48620 non-null  int64  \n",
    "    4   order_date         48620 non-null  object \n",
    "    5   order_time         48620 non-null  object \n",
    "    6   unit_price         48620 non-null  float64\n",
    "    7   total_price        48620 non-null  float64\n",
    "    8   pizza_size         48620 non-null  object \n",
    "    9   pizza_category     48620 non-null  object \n",
    "    10  pizza_ingredients  48620 non-null  object \n",
    "    11  pizza_name         48620 non-null  object \n",
    "    dtypes: float64(2), int64(3), object(7)\n",
    "    memory usage: 4.5+ MB\n",
    "\n",
    "## df.head() output\n",
    "    pizza_id\torder_id\tpizza_name_id\tquantity\torder_date\torder_time\tunit_price\ttotal_price\tpizza_size\tpizza_category\tpizza_ingredients\tpizza_name\n",
    "    0\t1\t1\thawaiian_m\t1\t01-01-2015\t11:38:36\t13.25\t13.25\tM\tClassic\tSliced Ham, Pineapple, Mozzarella Cheese\tThe Hawaiian Pizza\n",
    "    1\t2\t2\tclassic_dlx_m\t1\t01-01-2015\t11:57:40\t16.00\t16.00\tM\tClassic\tPepperoni, Mushrooms, Red Onions, Red Peppers,...\tThe Classic Deluxe Pizza\n",
    "    2\t3\t2\tfive_cheese_l\t1\t01-01-2015\t11:57:40\t18.50\t18.50\tL\tVeggie\tMozzarella Cheese, Provolone Cheese, Smoked Go...\tThe Five Cheese Pizza\n",
    "    3\t4\t2\tital_supr_l\t1\t01-01-2015\t11:57:40\t20.75\t20.75\tL\tSupreme\tCalabrese Salami, Capocollo, Tomatoes, Red Oni...\tThe Italian Supreme Pizza\n",
    "    4\t5\t2\tmexicana_m\t1\t01-01-2015\t11:57:40\t16.00\t16.00\tM\tVeggie\tTomatoes, Red Peppers, Jalapeno Peppers, Red O...\tThe Mexicana Pizza\n",
    "\n",
    "\n",
    "# Few Shot Examples\n",
    "\n",
    "## Example 1: \n",
    "    <input>\n",
    "        Show a bar plot of the 5 worst sold pizzas based on pizza name. Display also the ingredients of those pizzas on hover. Display the total number very big in the middle of each bar.\n",
    "    </input>\n",
    "    <output>\n",
    "        worst_sold = df.groupby('pizza_name', as_index=False)['quantity'].sum().nsmallest(5, 'quantity')\n",
    "        fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(\n",
    "                x=worst_sold['pizza_name'],\n",
    "                y=worst_sold['quantity'],\n",
    "                text=worst_sold['quantity'],\n",
    "                textposition='inside',\n",
    "                textfont=dict(size=24),\n",
    "                hovertext=worst_sold['pizza_name'].map(\n",
    "                    df.drop_duplicates('pizza_name').set_index('pizza_name')['pizza_ingredients']\n",
    "                ),\n",
    "                hoverinfo='text'\n",
    "                )\n",
    "            ]\n",
    "        ) \n",
    "    </output>\n",
    "\n",
    "## Example 2:\n",
    "    <input>\n",
    "        Show orders per hour (order_time) throughout the day.\n",
    "    </input>\n",
    "    <output>\n",
    "        df['order_time'] = pd.to_datetime(df['order_time'], format='%H:%M:%S').dt.hour\n",
    "        orders_per_hour = df.groupby('order_time', as_index=False)['order_id'].count()\n",
    "        fig = go.Figure(\n",
    "            data=[\n",
    "                go.Bar(\n",
    "                    x=orders_per_hour['order_time'],\n",
    "                    y=orders_per_hour['order_id'],\n",
    "                    text=orders_per_hour['order_id'],\n",
    "                    textposition='outside'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    </output>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_plot(df: pd.DataFrame, user_input: str) -> str: \n",
    "    \"\"\"\n",
    "    Generates a plotly figure based on the provided DataFrame and user input.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        user_input (str): The user input describing the desired plot.\n",
    "    \n",
    "    Returns:\n",
    "        Response: the python code generated by the OpenAI API as str\n",
    "    \"\"\"\n",
    "\n",
    "    # Capture df.info() output as a string\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    df_info_str = buf.getvalue()\n",
    "\n",
    "    # Create the response using the Responses API\n",
    "    response = openai_client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"developer\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": system_prompt},\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": user_input},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    code = response.output_text\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "user_input = \"Show a bar plot of the top 10 most sold pizzas based on pizza name. Display also the ingredients of those pizzas.\"\n",
    "# user_input = \"Show pizza ingredients as a pie chart. Only include ingredients that appear in more than 2% of total sales.\"\n",
    "# user_input = \"Create a time series line chart of total sales per month over the entire dataset.\"\n",
    "# user_input = \"Plot total revenue per pizza category as a horizontal bar chart, sorted by revenue.\"\n",
    "# user_input = \"Display a stacked bar chart of pizza quantities sold per category, broken down by pizza size.\"\n",
    "# user_input = \"Generate a line chart showing the cumulative revenue over time for the top 3 most popular pizza categories.\"\n",
    "# user_input = \"Show orders per hour throughout the day.\"\n",
    "# user_input = \"Create a heatmap of average quantity sold by pizza size and pizza category.\"\n",
    "# user_input = \"Compare monthly sales trends of 'The Hawaiian Pizza' and 'The Classic Deluxe Pizza' using a dual-line chart with date on the x-axis.\"\n",
    "\n",
    "code = generate_plot(df, user_input)\n",
    "print(code)\n",
    "fig = None\n",
    "exec(code)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
