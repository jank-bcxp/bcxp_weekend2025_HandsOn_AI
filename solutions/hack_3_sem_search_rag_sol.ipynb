{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Semantic Search & Retrieval Augmented Generation (RAG)\n",
    "\n",
    "## Finde die passende Pizza mit Semantic Search\n",
    "\n",
    "Task: Ein Kunde soll basierend auf der Beschreibung einer Speise eine passende Bestelloption finden k√∂nnen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install openai matplotlib scikit-learn umap-learn plotly faiss-cpu numpy tabulate pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict\n",
    "import io\n",
    "\n",
    "# Download Menu \n",
    "import urllib.request\n",
    "import os.path\n",
    "MENU_URL = \"https://raw.githubusercontent.com/jank-bcxp/bcxp_weekend2025_HandsOn_AI/refs/heads/main/menu.py\"\n",
    "urllib.request.urlretrieve(MENU_URL, os.path.basename(MENU_URL))\n",
    "# Download helpers\n",
    "HELPERS_URL = \"https://raw.githubusercontent.com/jank-bcxp/bcxp_weekend2025_HandsOn_AI/refs/heads/main/hack_helpers.py\"\n",
    "urllib.request.urlretrieve(HELPERS_URL, os.path.basename(HELPERS_URL))\n",
    "\n",
    "from menu import MENU\n",
    "from hack_helpers import plot_umap\n",
    "\n",
    "# Initialize OpenAI client\n",
    "from google.colab import userdata\n",
    "openai_client = OpenAI(api_key= userdata.get('openai_api_key'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings & Basic Similarity Search\n",
    "\n",
    "In der Einf√ºhrung zu LLMs haben wir gesehen, wie Begriffe in einen Vektorraum eingebettet (embedded) und numerisch dargestellt werden k√∂nnen. Der Vektor eines Wortes - das **Embedding** - repr√§sentiert dabei dessen Bedeutung. \n",
    "Bei einer **syntaktischen** Suche nach dem Begriff \"Unterkunft\" in einem Dokument, werden genau diejenigen W√∂rter gesucht, die Zeichen f√ºr Zeichen mit \"Unterkunft\" √ºbereinstimmen. Bei der **semantischen** Suche werden hingegen alle W√∂rter gesucht, die eine √§hnliche Bedeutung wie \"Unterkunft\" besitzen. Das sind diejenigen W√∂rter, die im Vektorraum 'nahe' am Vektor von \"Unterkunft\" liegen. Neben Unterkunft w√ºrden so auch Begriffe wie \"Ferienwohnung\" oder \"Hotel\" auftauchen. Nachfolgend werden wir sehen, wie eine semantische Suche implementiert werden kann. Da der Vektorraum ein kontinuierlicher Raum ist werden bei der semantischen Suche entweder die top-k Ergebnisse verwendet die am n√§chsten sind oder es wird ein fester Schwellenwert verwendet, der definiert ob ein Kandidat nah genug am gesuchten Begriff ist um als 'Match' zu gelten.\n",
    "\n",
    "Um Embeddings zu erstellen k√∂nnen unterschiedliche Sprachmodelle verwendet werden. Beispielsweise sind _SentenceTransformer_ eine ressourcen-schonende und frei verf√ºgbare Alternative zu kostenpflichtigen Modellen wie von OpenAI, die auch lokal laufen k√∂nnen. Der einfachheit halber verwenden wir hier aber die OpenAI API um Embeddings zu erzeugen.\n",
    "\n",
    "UMAP (Uniform Manifold Approximation and Projection) ist ein Verfahren zur Dimensionsreduktion, das hochdimensionale Vektoren ‚Äì z.‚ÄØB. Embeddings aus Sprache ‚Äì in einen niederdimensionalen Raum wie 2D f√ºr Darstellungszwecke abbildet. Es versucht dabei, semantische N√§he (z.‚ÄØB. zwischen Texten) m√∂glichst gut zu bewahren, indem es lokale Nachbarschaften erh√§lt.\n",
    "\n",
    "‚ö†Ô∏è Wichtig: Die sichtbare Distanz im 2D-Plot entspricht nicht exakt der tats√§chlichen √Ñhnlichkeit im urspr√ºnglichen Vektorraum. Die Projektion ist eine visuelle Ann√§herung, keine metrische 1:1-Abbildung.\n",
    "\n",
    "F√ºhre die n√§chste Zelle aus um f√ºr jeden Men√º Eintrag die N√§he zur User-Eingabe zu bestimmen und um die Embeddings der Speisen aus der Speisekarte und den User Input mittels UMAP in einem Plot zu visualisieren.\n",
    "\n",
    "**Aufgabe:** F√ºge der Karte einige Getr√§nke und Salate hinzu und beobachte wie sich diese in die UMAP Projektion einf√ºgen. F√ºge unpassende Nutzer-Eingaben ein und beobacht den Score und wie sich die Anfrage in die UMAP Projektion einf√ºgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üó£ Benutzereingabe\n",
    "user_input = \"Ich habe Lust auf eine spicy Pizza.\"\n",
    "\n",
    "# üßæ Strings zur Embedding-Vorbereitung\n",
    "menu_texts = [f\"{item['name']} ‚Äì {item['beschreibung']}\" for item in MENU]\n",
    "texts_to_embed = [user_input] + menu_texts  # User prompt + all items\n",
    "\n",
    "# üß† Embedding-Berechnung mit OpenAI\n",
    "response = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\", input=texts_to_embed\n",
    ")\n",
    "embeddings = [np.array(d.embedding) for d in response.data]\n",
    "\n",
    "# üßÆ Vektorvergleich (cosine similarity)\n",
    "user_embedding = embeddings[0] # User Prompt embedding\n",
    "menu_embeddings = embeddings[1:] # Menu embeddings\n",
    "# Hier wird die Cosine Similarity zwischen dem User-Embedding und den Men√º-Embeddings berechnet\n",
    "# F√ºr viele Men√º-Items und wechselnden Anfragen kann dies sehr ineffizient sein\n",
    "similarities = cosine_similarity([user_embedding], menu_embeddings)[0] \n",
    "\n",
    "# ü•á Sortierte Ergebnisse\n",
    "results = []\n",
    "for idx, score in sorted(enumerate(similarities), key=lambda x: x[1], reverse=True):\n",
    "    item = MENU[idx]\n",
    "    results.append(\n",
    "        {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"score\": round(score, 3),\n",
    "            \"description\": item[\"beschreibung\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# üìä Ausgabe als DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "plot_umap(user_embedding, menu_embeddings, MENU, similarity_scores=similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS f√ºr schnelle Similarity Search bei gro√üen Datenmengen\n",
    "\n",
    "**FAISS** (Facebook AI Similarity Search) ist eine Bibliothek f√ºr schnelle und skalierbare √§hnlichkeitssuche auf Vektoren.\n",
    "Sie erm√∂glicht eine effiziente Nearest-Neighbor-Suche ‚Äî n√ºtzlich f√ºr semantische Suche, Reccomendation Systems, Clustering usw.\n",
    "\n",
    "Hauptmerkmale:\n",
    "- Funktioniert mit hochdimensionalen Embeddings (z.‚ÄØB. von SentenceTransformers)\n",
    "- Erm√∂glicht Kosinus-√Ñhnlichkeit (√ºber normalisierte Vektoren und inneres Produkt) f√ºr semantische √Ñhnlichkeit\n",
    "- Skaliert auf Millionen oder Milliarden von Vektoren\n",
    "- Indizes k√∂nnen auf der Festplatte gespeichert und geladen werden ‚Äì Metadaten m√ºssen jedoch separat verwaltet werden\n",
    "\n",
    "Typischer Workflow:\n",
    "1.\tWandle deine Objekte (z.‚ÄØB. Texte) mit einem Embedding-Modell in dichte Vektoren um.\n",
    "2.\tSpeichere diese Vektoren in einem FAISS-Index (z.‚ÄØB. IndexFlatIP oder IndexHNSWFlat).\n",
    "3.\tKodierst du eine Anfrage (Query), kannst du die top-k √§hnlichsten Objekte suchen.\n",
    "\n",
    "**Aufgabe 1**: Finde ein Beispiel f√ºr eine User Query, f√ºr welches das Ergebnis mit dem besten √Ñhnlichkeitsscore nicht zur Query passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EMBEDDING SETUP ===\n",
    "# Wir wollen Embeddings erzeugen f√ºr Name + Beschreibung der Men√ºpunkte\n",
    "menu_texts = [f\"{item['name']}: {item['beschreibung']}\" for item in MENU]\n",
    "\n",
    "# Generiere die Embeddings f√ºr die Men√ºtexte mit OpenAI\n",
    "response = openai_client.embeddings.create(model=\"text-embedding-3-small\", input=menu_texts)\n",
    "embeddings = np.array([d.embedding for d in response.data], dtype=np.float32)\n",
    "\n",
    "# === FAISS VECTOR INDEX ===\n",
    "# Normalisierung wird ben√∂tigt um zusammen mit inner product (dot product) die Cosine Similarity zu berechnen, welche die √Ñhnlichkeit der Vektoren beschreibt\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dim = embeddings.shape[1] # Dimension der Vektoren\n",
    "index = faiss.IndexFlatIP(dim) # Initialisierung des Indexes mit inner product (dot product)\n",
    "index.add(embeddings) # Vektoren dem Index hinzuf√ºgen\n",
    "\n",
    "# === MEN√ú ABFRAGE ===\n",
    "def retrieve_menu_items(query: str, top_k: int = 10) -> List[Dict]:\n",
    "    # Step 1: Generiere Embedding f√ºr die User Abfrage\n",
    "    response = openai_client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\", input=[query]\n",
    "    )\n",
    "    query_vec = np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # Step 2: Normalisiere den Vektor f√ºr die Cosine Similarity\n",
    "    faiss.normalize_L2(query_vec)\n",
    "\n",
    "    # Step 3: Suche im FAISS Index nach den √§hnlichsten Vektoren\n",
    "    distances, indices = index.search(query_vec, top_k)\n",
    "\n",
    "    # Step 4: Erstelle eine Liste von Men√ºpunkten mit den entsprechenden √Ñhnlichkeitswerten\n",
    "    return list(zip(indices[0], distances[0]))\n",
    "\n",
    "print(\"FAISS Index Description\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Index Type      : {type(index).__name__}\")\n",
    "print(f\"Dimension (D)   : {index.d}\")\n",
    "print(f\"Vectors Stored  : {index.ntotal}\")\n",
    "print(\"-\" * 30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXAMPLE USAGE ===\n",
    "user_query = \"Ich h√§tte gerne etwas mit Pilzen aber ohne Tr√ºffel\"\n",
    "retrieved_results = retrieve_menu_items(user_query)\n",
    "for idx, score in retrieved_results:\n",
    "    print(f\"- {MENU[idx]['name']} (score: {score}): {MENU[idx]['beschreibung']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG) mit FAISS und OpenAI API\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) ist ein KI-Ansatz, der generative Sprachmodelle (z.‚ÄØB. GPT) mit einer externen Wissensquelle kombiniert. Dabei werden relevante Informationen zur Benutzeranfrage zuerst aus einer Datenbank oder Dokumentensammlung _retrieved_ (abgerufen), wie in folgendem Beispiel aus unserem FAISS Index, und anschlie√üend von einem genertiven Modell in die Generierung der Antwort einbezogen. \n",
    "\n",
    "- Ein RAG Ansatz kann verwendet werden, wenn auf einem gro√üen Datensatz gearbeitet werden muss, welcher zu gro√ü f√ºr den Kontext des Sprachmodells ist.\n",
    "- Au√üerdem k√∂nnen durch die Reduzierung des LLM Inputs auf relevante Eintr√§ge Kosten gesenkt werden (Anzahl der Input-Tokens sinkt).\n",
    "\n",
    "**Aufgabe:** √úberlege dir Vor und Nachteile eines RAG Ansatzes. In welchen F√§llen kann der RAG Ansatz zu schlechten Ergebnissen f√ºhren? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_items_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"category\": {\"type\": \"string\"},\n",
    "                    \"price\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"id\", \"name\", \"description\", \"category\", \"price\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"items\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "user_query = \"Ich h√§tte gerne etwas mit Pilzen aber ohne Tr√ºffel.\"\n",
    "retrieved_results = retrieve_menu_items(user_query)\n",
    "print(\"Vorselektierte Eintr√§ge aus dem Men√º:\\n\")\n",
    "for idx, score in retrieved_results:\n",
    "    print(f\"- {MENU[idx]['name']} (score: {score}): {MENU[idx]['beschreibung']}\")\n",
    "retrieved_menu_items = [MENU[idx] for idx, _ in retrieved_results]\n",
    "\n",
    "# üß† API-Aufruf\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Du bist ein digitaler Kellner. W√§hle genau eine passende Speise aus den folgenden vorselektierten Speisen aus, welche die Kriterien aus der Kundenbestellung am ehesten erf√ºllt:\\n{json.dumps(retrieved_menu_items, ensure_ascii=False)}\\n\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{user_query}\",\n",
    "        },\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"menu_item\",\n",
    "            \"schema\": menu_items_schema,\n",
    "            \"strict\": True,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "recommendations = json.loads(response.output_text)[\"items\"]\n",
    "\n",
    "# üì§ Ausgabe anzeigen\n",
    "print(\"\\nEmpfohlene Speise:\")\n",
    "for item in recommendations:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Local Embedding Generation\n",
    "\n",
    "Nachfolgend findet sich ein Beispiel mit der Verwendung eines lokalen Sentence-Transformer Modells f√ºr das Erstellen der Embeddings der Speisekarte und des User-Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hack_helpers import plot_umap\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# üó£ 2. Benutzereingabe\n",
    "user_input = \"Ich habe Lust auf eine spicy Pizza.\"\n",
    "\n",
    "# üß† 3. Modell laden (z.‚ÄØB. multilingual + performant)\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# üßÆ 4. Embeddings berechnen\n",
    "menu_texts = [f\"{item['name']} ‚Äì {item['beschreibung']}\" for item in MENU] # Hier wird die Speisekarte in emeddable Strings umgewandelt\n",
    "menu_embeddings = model.encode(menu_texts, convert_to_tensor=True) # Hier werden die Embeddings f√ºr die gesamte Speisekarte berechnet\n",
    "user_embedding = model.encode(user_input, convert_to_tensor=True) # Hier wird das Embedding f√ºr die Benutzereingabe berechnet\n",
    "\n",
    "# TODO Print ein Embedding um die Vectorrepr√§sentation zu sehen\n",
    "# print(user_embedding)\n",
    "\n",
    "# üîé 5. √Ñhnlichkeit berechnen\n",
    "cos_scores = util.cos_sim(user_embedding, menu_embeddings)[0] # Hier wird die √Ñhnlichkeit zwischen der Benutzereingabe und den Speisen mittels cosine similarity berechnet\n",
    "\n",
    "# ü•á 6. Sorted results\n",
    "top_results = sorted(list(enumerate(cos_scores)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# üì§ 7. Ausgabe strukturieren\n",
    "results = []\n",
    "for idx, score in top_results:\n",
    "    item = MENU[idx]\n",
    "    results.append(\n",
    "        {\n",
    "            \"name\": item[\"name\"],\n",
    "            \"score\": round(score.item(), 3),\n",
    "            \"description\": item[\"beschreibung\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# üìä Als DataFrame anzeigen\n",
    "pd.set_option(\"display.width\", 200)  # Increase pd width to print correctly\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "plot_umap(user_embedding, menu_embeddings, MENU, similarity_scores=cos_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
